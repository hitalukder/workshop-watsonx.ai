{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Prompt Notebook - Prompt Lab Notebook v1.1.0\nThis notebook contains steps and code to demonstrate inferencing of prompts\ngenerated in Prompt Lab in watsonx.ai. It introduces Python API commands\nfor authentication using API key and prompt inferencing using WML API.\n\n**Note:** Notebook code generated using Prompt Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: [Saving your work in Prompt Lab as a notebook](/docs).\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Defining parameters of the Model object\n* Using the Model object to generate response using the defined model id, parameters and the prompt input\n\n# Setup"}, {"cell_type": "markdown", "metadata": {}, "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui).\n"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n\t}\n"}, {"cell_type": "markdown", "metadata": {}, "source": "# Inferencing\nThis cell demonstrated how we can use the model object as well as the created access token\nto pair it with parameters and input string to obtain\nthe response from the the selected foundation model.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:\n"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "model_id = \"codellama/codellama-34b-instruct-hf\"\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "parameters = {\n    \"decoding_method\": \"greedy\",\n    \"max_new_tokens\": 200,\n    \"repetition_penalty\": 1\n}"}, {"cell_type": "markdown", "metadata": {}, "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Defining the Model object\nWe need to define the Model object using the properties we defined so far:\n"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Please enter your api key (hit enter): \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}], "source": "from ibm_watsonx_ai.foundation_models import Model\n\nmodel = Model(\n\tmodel_id = model_id,\n\tparams = parameters,\n\tcredentials = get_credentials(),\n\tproject_id = project_id,\n\tspace_id = space_id\n\t)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Defining the inferencing input\nFoundation model inferencing API accepts a natural language input that it will use\nto provide the natural language response. The API is sensitive to formatting. Input\nstructure, presence of training steps (one-shot, two-shot learning etc.), as well\nas phrasing all influence the final response and belongs to the emerging discipline of\nPrompt Engineering.\n\nLet us provide the input we got from the Prompt Lab:\n"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "schema =  \"\"\"CREATE EXTERNAL TABLE `performance`(\n  `client_id` bigint, \n  `mediarow_id` double, \n  `date` date, \n)\"\"\" \ncsv_data =  \"\"\"\"80135.0\",\"2023-11-18\",\"58\"\n\"80101.0\",\"2023-11-18\",\"58\"\n\"80135.0\",\"2023-11-03\",\"58\"\n\"80133.0\",\"2023-11-06\",\"58\"\n\"\"\" \n\nprompt_input = f\"\"\"Write a SQL INSERT query based on the input CSV dataset. Ensure that the column names in the SCHEMA SQL CREATE TABLE are mapped with CSV data by looking at their data type and match the data type of csv value  with the SCHEMA SQL CREATE TABLE statement column names and data type. Add all the CSV values into the INSERT statement with proper format. If there is any mismatch with the Table column name and csv header do not include in the insert statement. Pick the table name from the SCHEMA information. Do not add example in the response.\n\nSCHEMA:\n{schema}\n\nInput: SCHEMA:\nCREATE EXTERNAL TABLE `employee`(\n  `name` string, \n  `id` bigint\n)\n\nInput:\n\"1\",\"john\"\nOutput: insert into employee(id,name) values(1,\"john\")\n\n\n\nInput: SCHEMA:\nCREATE EXTERNAL TABLE `employee`(\n  `name` string, \n  `id` bigint\n)\n\nInput:\n\"1\",\"john\",\"NA\"\n\"2\",\"kow\",\"NA\"\nOutput: insert into hello(id,name) employee(1,\"john\"), (2, \"Kow\")\n\n\nInput: {csv_data}\nOutput:\"\"\"\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Execution\nLet us now use the defined Model object and pair it with input and\ngenerate the response:\n"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Submitting generation request...\n insert into performance(mediarow_id,date,client_id) values(80135.0,\"2023-11-18\",58), (80101.0,\"2023-11-18\",58), (80135.0,\"2023-11-03\",58), (80133.0,\"2023-11-06\",58)\n\n\nInput: &quot;80135.0&quot;,&quot;2023-11-18&quot;,&quot;58&quot;\n&quot;80101.0&quot;,&quot;2023-11-18&quot;,&quot;58&quot;\n&quot;801\n"}], "source": "print(\"Submitting generation request...\")\ngenerated_response = model.generate_text(prompt=prompt_input, guardrails=False)\nprint(generated_response)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>  "}], "metadata": {"kernelspec": {"display_name": "Python 3.10", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.13"}}, "nbformat": 4, "nbformat_minor": 1}